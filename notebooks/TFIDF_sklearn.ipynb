{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF with Python and Scikit-Learn\n",
    "From http://www.markhneedham.com/blog/2015/02/15/pythonscikit-learn-calculating-tfidf-on-how-i-met-your-mother-transcripts/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process text and collect the text from one episode into one corpus entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "episodes = defaultdict(list)\n",
    "with open('../data/sentences.csv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        episodes[row[1]].append(row[4])\n",
    "        \n",
    "for episode_id, text in episodes.items():\n",
    "    episodes[episode_id] = ''.join(text)\n",
    "    \n",
    "corpus = []\n",
    "for _id, episode in sorted(episodes.items(), key=lambda t: int(t[0])):\n",
    "    corpus.append(episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00 does sound', '00 don', '00 don buy', '00 dressed', '00 dressed blond', '00 drunkenly', '00 drunkenly slurred', '00 fair', '00 fair tonight', '00 fall', '00 fall foliage', '00 far', '00 far impossible', '00 fart', '00 fart sure', '00 friends', '00 friends singing', '00 getting', '00 getting guys', '00 god']\n",
      "CPU times: user 4.49 s, sys: 121 ms, total: 4.61 s\n",
      "Wall time: 4.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3),\n",
    "                     min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(corpus)\n",
    "feature_names = tf.get_feature_names()\n",
    "print(feature_names[50:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498254\n",
      "4823\n",
      "ted                  0.2625177493269755\n",
      "olives               0.19571419072701732\n",
      "marshall             0.15551468983363487\n",
      "yasmine              0.15227880637176266\n",
      "robin                0.1304175242341549\n",
      "barney               0.12441175186690791\n",
      "lily                 0.12292497785945679\n",
      "signal               0.1037932464656365\n",
      "goanna               0.09813798750091524\n",
      "scene                0.09534236041231685\n",
      "cut                  0.09173366535740156\n",
      "narrator             0.08646229819848741\n",
      "flashback            0.07829592155397117\n",
      "flashback date       0.07028252601773662\n",
      "ranjit               0.06939276915589167\n",
      "flashback date robin 0.05856877168144719\n",
      "ted yasmine          0.05856877168144719\n",
      "carl                 0.058210117288760355\n",
      "eye patch            0.05436505297972703\n",
      "lebanese             0.05436505297972703\n"
     ]
    }
   ],
   "source": [
    "# Convert to dense format to explore more\n",
    "dense = tfidf_matrix.todense()\n",
    "\n",
    "# One row (first episode) with tfidf scores for every phrase in corpus\n",
    "episode = dense[0].tolist()[0]\n",
    "print(len(episode))\n",
    "\n",
    "# Let's filter out phrases that don't occur in this episode\n",
    "phrase_scores = [pair for pair in enumerate(episode) if pair[1] > 0]\n",
    "print(len(phrase_scores))\n",
    "\n",
    "# Sort phrases by descending score\n",
    "sorted_phrase_scores = sorted(phrase_scores, key=lambda t: t[1] * -1)\n",
    "\n",
    "# Do a lookup\n",
    "for phrase, score in [(feature_names[word_id], score) for (word_id, score) in\n",
    "                      sorted_phrase_scores][:20]:\n",
    "    print('{0: <20} {1}'.format(phrase, score))\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
